# üß† Primer Proyecto de Inteligencia Artificial ‚Äî ITCR (Sede San Carlos)

Un sistema distribuido de microservicios que integra modelos de Machine Learning con capacidades conversacionales mediante un coordinador LLM local. La arquitectura permite consultar y explorar resultados predictivos usando lenguaje natural.

## Caracter√≠sticas T√©cnicas

- **Arquitectura de Microservicios**: APIs REST independientes para cada modelo ML
- **Coordinador LLM Inteligente**: Integraci√≥n con Ollama/LLaMA para procesamiento de lenguaje natural
- **Sistema de Logging Centralizado**: Monitoreo y debugging profesional con rotaci√≥n autom√°tica
- **Extracci√≥n Inteligente de Par√°metros**: Parsing autom√°tico de consultas en lenguaje natural
- **Interfaz Conversacional**: Comunicaci√≥n natural entre usuario y modelos predictivos
- **Manejo Robusto de Errores**: Fallbacks autom√°ticos y validaci√≥n de entrada

## Modelos de Machine Learning

| Modelo                              | Algoritmo               | Dominio de Aplicaci√≥n                            | Estado    |
|:-----------------------------------:|:-----------------------:|:--------------------------------------------------|:----------|
| `prophet_bitcoin_v2_*.pkl`         | Prophet (Facebook)      | Predicci√≥n temporal de criptomonedas            | ‚úÖ Activo |
| `catboost_avocado_*.pkl`            | CatBoost               | Predicci√≥n de precios de commodities agr√≠colas   | ‚úÖ Activo |
| `knn_movie_recommendation_*.pkl`    | K-Nearest Neighbors    | Sistema de recomendaci√≥n por similitud          | ‚úÖ Activo |
| `random_forest_flights_*.pkl`       | Random Forest          | Predicci√≥n de retrasos en transporte a√©reo      | ‚úÖ Activo |
| `decision_tree_acv_*.pkl`           | Decision Tree          | Evaluaci√≥n de riesgo m√©dico                      | ‚úÖ Activo |
| `bitcoin_random_forest_*.pkl`       | Random Forest          | Predicci√≥n de criptomonedas (versi√≥n anterior)  | üì¶ Legacy |

### Tecnolog√≠as de ML Implementadas
- **Series Temporales**: Prophet para an√°lisis de tendencias y estacionalidad
- **Gradient Boosting**: CatBoost para manejo de features categ√≥ricas
- **Ensemble Methods**: Random Forest para robustez predictiva
- **Sistemas de Recomendaci√≥n**: KNN con m√©tricas de similitud personalizadas
- **√Årboles de Decisi√≥n**: Interpretabilidad para dominio m√©dico

### Modelos de Deep Learning (Nuevos)
Se han a√±adido varios modelos basados en Deep Learning para ampliar las capacidades del sistema, especialmente en reconocimiento facial, detecci√≥n de emociones y transcripci√≥n de voz.

| Modelo / Archivo                         | Framework / Formato | Dominio de Aplicaci√≥n                        | Estado    |
|:----------------------------------------:|:-------------------:|:--------------------------------------------:|:---------:|
| `dl_models/emotion_model.keras`          | Keras / TensorFlow  | Detecci√≥n de emoci√≥n facial (imagen/video)   | ‚úÖ Activo |
| `dl_models/asr/mariantonieta_asr_ctc.h5` | Keras (CTC)         | Reconocimiento autom√°tico de voz (ASR)       | ‚úÖ Activo |
| Modelo de veh√≠culos (YOLOv8/Ultralytics) | YOLO / PyTorch     | Detecci√≥n y clasificaci√≥n de veh√≠culos       | ‚úÖ Activo |

Estas incorporaciones permiten:
- Clasificaci√≥n de emociones faciales en tiempo real mediante un modelo Keras.
- Transcripci√≥n de audio a texto con un modelo CTC (ASR) para integrarlo con el coordinador LLM.
- Detecci√≥n y clasificaci√≥n autom√°tica de veh√≠culos en im√°genes usando YOLOv8/Ultralytics.

Nota: Algunos modelos (ONNX) requieren `onnxruntime` para ejecuci√≥n eficiente. Ver secci√≥n de instalaci√≥n para m√°s detalles.

## Stack Tecnol√≥gico

### Backend & APIs
- **Python 3.9+**: Lenguaje principal del sistema
- **FastAPI**: Framework moderno para APIs REST con validaci√≥n autom√°tica
- **Uvicorn**: Servidor ASGI de alto rendimiento
- **Pydantic**: Validaci√≥n de datos y serializaci√≥n tipo-segura

### Machine Learning
- **Prophet**: An√°lisis de series temporales con componentes estacionales
- **CatBoost**: Gradient boosting con manejo nativo de features categ√≥ricas  
- **Scikit-learn**: Biblioteca est√°ndar para algoritmos ML cl√°sicos
- **Joblib**: Persistencia optimizada de modelos ML
- **Pandas & NumPy**: Manipulaci√≥n y procesamiento de datos

- **TensorFlow & Keras**: Entrenamiento e inferencia de modelos deep learning (p.ej. clasificaci√≥n de emociones, ASR CTC)
- **Ultralytics (YOLO)**: Detecci√≥n de objetos en im√°genes y video (inferencia r√°pida)
- **Tools para ASR**: Librer√≠as y utilidades para evaluaci√≥n de ASR (e.g., `jiwer` para WER)

### LLM & Procesamiento de Lenguaje
- **Ollama**: Runtime local para modelos de lenguaje
- **LLaMA**: Arquitectura de transformer para comprensi√≥n del lenguaje
- **Extracci√≥n de entidades**: Parsing inteligente de par√°metros temporales y num√©ricos

### Monitoreo & Logging
- **Sistema de logging centralizado**: Configuraci√≥n unificada con rotaci√≥n autom√°tica
- **M√©tricas de rendimiento**: Tracking de timing y throughput por endpoint
- **Health checks**: Monitoreo autom√°tico del estado de modelos
- **Error handling**: Manejo robusto de excepciones con fallbacks

### Frontend & UI
- **React**: Framework de interfaz de usuario moderna
- **TypeScript**: Tipado est√°tico para JavaScript
- **Vite**: Build tool optimizado para desarrollo
- **Node.js + npm**: Runtime y gesti√≥n de dependencias

## Instalaci√≥n y Configuraci√≥n

### Requisitos del Sistema
- **Python 3.9+** (recomendado 3.11+)
- **Node.js 16+** y npm
- **Git** para control de versiones
- **4GB+ RAM** para modelos ML
- **macOS/Linux**: Homebrew para dependencias adicionales

### Configuraci√≥n del Entorno Python

```bash
# Clonar repositorio
git clone https://github.com/SMatey/Mariantonieta-IA.git
cd Mariantonieta-IA

# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate   # macOS/Linux (zsh compatible)

# Instalar dependencias
pip install -r requirements.txt
```

### Variables de Entorno

Configura estas variables para personalizar el comportamiento del sistema:

```bash
# Archivo .env (no incluir en Git)
ENV=development
AZURE_FACE_KEY="your_api_key"
AZURE_FACE_ENDPOINT="https://<endpoint>.cognitiveservices.azure.com/"
LLM_HOST="http://localhost:11434"
API_BASE_URL="http://localhost:8000"
LOG_LEVEL="INFO"
MAX_LOG_SIZE_MB=5
LOG_BACKUP_COUNT=5
```

### Configuraci√≥n del LLM Local (Ollama)

```bash
# macOS (Homebrew)
brew install ollama

# Iniciar servicio
ollama serve

# Descargar modelo recomendado
ollama pull llama3.1:8b
```

## Ejecuci√≥n del Sistema

### M√©todo Unificado (Recomendado)

```bash
# Ejecutar todos los servicios
chmod +x run_all.sh
./run_all.sh
```

### Servicios Individuales

#### 1. API Backend (Puerto 8000)
```bash
source venv/bin/activate
./run_api.sh  # Script optimizado con uvicorn
```

### 2) Coordinador LLM

```bash
source venv/bin/activate
python llm/coordinator.py
```

#### 3. Frontend (Puerto 5173)
```bash
cd frontend
npm install
npm run dev
```

### Verificaci√≥n del Sistema

```bash
# Health checks de las APIs
curl http://localhost:8000/health      # API principal
curl http://localhost:8000/models/bitcoin/health
curl http://localhost:8000/models/avocado/health

# Estado del LLM
curl http://localhost:11434/api/tags   # Ollama models
```

## Capacidades del Sistema

### Procesamiento de Lenguaje Natural
- **Extracci√≥n temporal**: Reconocimiento autom√°tico de fechas relativas y absolutas
- **Parsing de par√°metros**: Identificaci√≥n inteligente de valores num√©ricos y categor√≠as
- **Contextualizaci√≥n**: Interpretaci√≥n de consultas ambiguas con context-awareness
- **Respuestas explicativas**: Generaci√≥n de interpretaciones detalladas de resultados

### APIs de Predicci√≥n Disponibles
- **An√°lisis temporal**: Predicciones de series de tiempo con intervalos de confianza
- **Commodities agr√≠colas**: Predicci√≥n de precios con features de mercado
- **Sistemas de recomendaci√≥n**: Filtrado colaborativo y por contenido
- **An√°lisis de riesgo**: Evaluaci√≥n probabil√≠stica en dominios m√©dicos
- **Transporte a√©reo**: Predicci√≥n de retrasos con factores meteorol√≥gicos

### Arquitectura de Microservicios
- **Escalabilidad horizontal**: Cada modelo puede escalarse independientemente
- **Tolerancia a fallos**: Fallbacks autom√°ticos y circuit breakers
- **Load balancing**: Distribuci√≥n de carga entre instancias
- **Versionado**: Soporte para m√∫ltiples versiones de modelos simult√°neamente

## Arquitectura del Sistema

```
proyecto/
‚îú‚îÄ‚îÄ api/                           # üî• Microservicios REST
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Coordinador principal de APIs
‚îÇ   ‚îú‚îÄ‚îÄ config_logger.py          # Sistema de logging centralizado
‚îÇ   ‚îú‚îÄ‚îÄ constants.py              # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ routes/                   # Endpoints por dominio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bitcoin_api.py        # API de criptomonedas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ avocado_api.py        # API de commodities agr√≠colas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ movies_api.py         # API de recomendaciones
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ flights_api.py        # API de transporte a√©reo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ acv_api.py            # API m√©dica de riesgo
‚îÇ   ‚îî‚îÄ‚îÄ models/                   # Esquemas Pydantic
‚îú‚îÄ‚îÄ llm/                          # üß† Coordinador LLM
‚îÇ   ‚îú‚îÄ‚îÄ coordinator.py            # Orquestador inteligente
‚îÇ   ‚îî‚îÄ‚îÄ extract_params.py        # Extracci√≥n de par√°metros NLP
‚îú‚îÄ‚îÄ ml_models/                    # ü§ñ Modelos ML serializados
‚îÇ   ‚îú‚îÄ‚îÄ prophet_bitcoin_v2_*.pkl  # Series temporales
‚îÇ   ‚îú‚îÄ‚îÄ catboost_avocado_*.pkl    # Gradient boosting
‚îÇ   ‚îî‚îÄ‚îÄ *.pkl                     # Otros modelos entrenados
‚îú‚îÄ‚îÄ logs/                         # üìã Sistema de logging
‚îÇ   ‚îú‚îÄ‚îÄ main_api.log              # Log del coordinador
‚îÇ   ‚îú‚îÄ‚îÄ *_api.log                 # Logs por microservicio
‚îÇ   ‚îî‚îÄ‚îÄ README.md                 # Documentaci√≥n de logs
‚îú‚îÄ‚îÄ frontend/                     # üíª Interfaz React
‚îÇ   ‚îú‚îÄ‚îÄ src/components/           # Componentes UI
‚îÇ   ‚îî‚îÄ‚îÄ package.json              # Dependencias frontend
‚îú‚îÄ‚îÄ data/                         # üìä Datasets y ejemplos
‚îú‚îÄ‚îÄ notebooks/                    # üìö An√°lisis exploratorio
‚îî‚îÄ‚îÄ tests/                        # üß™ Suite de pruebas
```

### Flujo de Datos
1. **Usuario** ‚Üí Frontend React
2. **Frontend** ‚Üí Coordinador LLM (puerto 8001)
3. **Coordinador** ‚Üí Extracci√≥n de par√°metros NLP
4. **Coordinador** ‚Üí API espec√≠fica (puerto 8000)
5. **API** ‚Üí Modelo ML + Logging
6. **Respuesta** ‚Üí Usuario con interpretaci√≥n

## Monitoreo y Debugging

### Sistema de Logging
- **Logging centralizado**: Configuraci√≥n unificada en `api/config_logger.py`
- **Rotaci√≥n autom√°tica**: Archivos de m√°ximo 5MB con 5 backups
- **Niveles configurables**: INFO, ERROR, WARNING, DEBUG
- **Sin output en consola**: Logs exclusivamente en archivos para interfaces limpias

### M√©tricas de Rendimiento
```bash
# Monitoreo en tiempo real
tail -f logs/main_api.log logs/bitcoin_api.log

# An√°lisis de errores
grep "ERROR" logs/*.log

# Estad√≠sticas de predicciones
grep "Prediction" logs/*_api.log | wc -l
```

### Health Checks Automatizados
- **Estado de modelos**: Verificaci√≥n de carga exitosa
- **Conectividad LLM**: Pruebas de comunicaci√≥n con Ollama
- **M√©tricas de memoria**: Uso de recursos por modelo
- **Endpoints de diagn√≥stico**: `/health` en cada microservicio

## Troubleshooting

### Problemas Comunes

#### Errores de Dependencias
```bash
# ModuleNotFoundError
source venv/bin/activate
pip install -r requirements.txt --upgrade

# Verificar instalaci√≥n
python -c "import fastapi, prophet, catboost; print('‚úÖ Dependencies OK')"
```

#### Problemas con Ollama
```bash
# Verificar estado del servicio
ollama ps
ollama list

# Logs de Ollama
tail -f ~/.ollama/logs/server.log

# Reiniciar servicio
pkill ollama && ollama serve
```

#### Issues del Frontend
```bash
# Limpiar cache y reinstalar
cd frontend
rm -rf node_modules package-lock.json
npm install
npm run dev
```

### Configuraci√≥n de Desarrollo

#### Variables de Debug
```bash
export LOG_LEVEL="DEBUG"
export FASTAPI_DEBUG="true"
export LLM_TIMEOUT="30"
```

#### Pruebas de Conectividad
```bash
# Test API principal
curl -X GET http://localhost:8000/health | jq

# Test coordinador LLM
curl -X POST http://localhost:8001/query \
  -H "Content-Type: application/json" \
  -d '{"query": "¬øCu√°l es el precio de Bitcoin?"}'
```


## Informaci√≥n del Proyecto

### Equipo de Desarrollo
- **Sebastian Matey** 
- **Liz Salazar** 
- **Roosevelt P√©rez** 

### Instituci√≥n
**Instituto Tecnol√≥gico de Costa Rica (TEC)**  
Sede San Carlos - Escuela de Ingenier√≠a en Computaci√≥n

### Tecnolog√≠as y Licencias
- **Repositorio**: Mariantonieta-IA (GitHub)
- **Licencia**: MIT License
- **Stack principal**: Python 3.11, FastAPI, React 18, TypeScript
- **ML Stack**: Prophet, CatBoost, Scikit-learn

**√öltima actualizaci√≥n**: 1 de diciembre de 2025  




