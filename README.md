# ğŸ§  Primer Proyecto de Inteligencia Artificial â€” ITCR (Sede San Carlos)

Un sistema distribuido compuesto por microservicios de Machine Learning y un coordinador LLM local. El objetivo es combinar modelos predictivos tradicionales con capacidades conversacionales para que los usuarios exploren y consulten resultados mediante lenguaje natural.

## Destacado
- Arquitectura basada en microservicios (API REST para modelos)
- Coordinador inteligente que integra un LLM local (Ollama / LLaMA) para diÃ¡logo y explicaciÃ³n
- Modelos especializados para regresiÃ³n, clasificaciÃ³n, recomendaciÃ³n y **series de tiempo**
- Nuevo modelo Prophet para predicciones temporales de Bitcoin
- Interfaz conversacional para consultas en lenguaje natural

## Modelos incluidos

| Modelo                           | Tipo                    | PropÃ³sito                                         | Estado    |
|:--------------------------------:|:-----------------------:|:--------------------------------------------------|:----------|
| `prophet_bitcoin_v2_*.pkl`      | **Series de Tiempo**   | **PredicciÃ³n temporal del precio del Bitcoin**   | âœ… Activo |
| `knn_movie_recommendation_model.pkl` | RecomendaciÃ³n      | Sugerencia de pelÃ­culas segÃºn preferencias       | âœ… Activo |
| `random_forest_properties_*.pkl` | RegresiÃ³n             | PredicciÃ³n del precio de propiedades             | âœ… Activo |
| `ACV_decision_tree_model.pkl`    | ClasificaciÃ³n          | DetecciÃ³n de riesgo de accidente cerebrovascular | âœ… Activo |
| `bitcoin_random_forest_*.pkl`    | RegresiÃ³n              | PredicciÃ³n Bitcoin (modelo anterior)             | ğŸ“¦ Legacy |

> **Nuevo**: El modelo de Bitcoin ahora usa **Prophet** para anÃ¡lisis de series temporales, permitiendo predicciones mÃ¡s precisas con tendencias estacionales y intervalos de confianza.

## Requisitos

- Python 3.9+ (recomendado)
- pip, virtualenv (o venv)
- Node.js + npm (para el frontend)
- macOS: Homebrew (para instalar Ollama si se usa)

### Dependencias principales nuevas:
- **Prophet**: Para modelos de series temporales
- **joblib**: Para carga optimizada de modelos ML
- **FastAPI**: APIs REST modernas y eficientes

Instala dependencias Python:

```bash
python3 -m venv venv
source venv/bin/activate   # macOS / Linux (zsh compatible)
pip install -r requirements.txt
```

## Variables de entorno (recomendadas)

Exporta estas variables en tu shell o crea un archivo `.env` (no incluir en Git):

```bash
export ENV=development
export AZURE_FACE_KEY="tu_api_key"
export AZURE_FACE_ENDPOINT="https://<endpoint>.cognitiveservices.azure.com/"
export LLM_HOST="http://localhost:8001"
export API_BASE_URL="http://localhost:8080"
```

## ConfiguraciÃ³n del LLM (opcional: Ollama)

Si quieres correr un LLM local con Ollama (opcional):

```bash
# macOS (Homebrew)
brew install ollama
ollama pull llama3:3b

# Ejecutar el modelo para pruebas
ollama run llama3:3b
```

Dependiendo de tu arquitectura y recursos, puedes elegir otro modelo o servicio. El coordinador LLM del repo asume que hay un endpoint local en `LLM_HOST`.

## EjecuciÃ³n â€” servicios individuales

### 1) Backend (API de modelos) â€” **Recomendado**

```bash
source venv/bin/activate
./run_api.sh  # Script optimizado que usa uvicorn correctamente
```

O manualmente:
```bash
source venv/bin/activate
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### 2) Coordinador LLM

```bash
source venv/bin/activate
python llm/coordinator.py
```

### 3) Frontend (interfaz)

```bash
cd frontend
npm install
npm run dev
```

## Nuevas funcionalidades

### ğŸ”® Predicciones temporales de Bitcoin
El nuevo modelo Prophet permite consultas como:
- "Â¿CuÃ¡l serÃ¡ el precio de Bitcoin maÃ±ana?"
- "Predice Bitcoin para la prÃ³xima semana"
- "Â¿QuÃ© precio tendrÃ¡ Bitcoin el 1 de enero de 2025?"

### ğŸ¤– Coordinador inteligente mejorado
- ExtracciÃ³n automÃ¡tica de fechas y parÃ¡metros
- Respuestas contextuales segÃºn el tipo de modelo
- Manejo de errores y respaldos automÃ¡ticos

## Script unificado (run_all.sh)

Hay un script de conveniencia `run_all.sh` que arranca los componentes en segundo plano:

```bash
chmod +x run_all.sh
./run_all.sh
```

El script incluye:
- âœ… ActivaciÃ³n automÃ¡tica del entorno virtual
- âœ… Inicio de la API optimizada con `uvicorn`
- âœ… ConfiguraciÃ³n correcta de puertos y hosts
- âœ… Manejo de errores y dependencias

## Estructura del proyecto

```
proyecto/
â”œâ”€â”€ api/                     # ğŸ”¥ APIs REST para modelos ML
â”‚   â”œâ”€â”€ main.py             # Entrada principal de la API
â”‚   â”œâ”€â”€ constants.py        # ğŸ†• Constantes centralizadas
â”‚   â”œâ”€â”€ routes/             # Rutas especÃ­ficas por modelo
â”‚   â”‚   â”œâ”€â”€ bitcoin_api.py  # ğŸ”® API Prophet para Bitcoin
â”‚   â”‚   â”œâ”€â”€ movies_api.py   # ğŸ¬ API recomendaciones
â”‚   â”‚   â””â”€â”€ properties_api.py # ğŸ  API predicciÃ³n propiedades
â”‚   â””â”€â”€ core/               # ConfiguraciÃ³n central
â”œâ”€â”€ llm/                    # ğŸ§  Coordinador LLM mejorado
â”‚   â””â”€â”€ coordinator.py      # ğŸ†• Coordinador con extracciÃ³n inteligente
â”œâ”€â”€ frontend/               # ğŸ’» Interfaz React
â”œâ”€â”€ models/                 # ğŸ¤– Modelos ML entrenados
â”‚   â”œâ”€â”€ prophet_bitcoin_v2_*.pkl  # ğŸ†• Modelo Prophet
â”‚   â”œâ”€â”€ knn_movie_*.pkl           # Recomendaciones
â”‚   â””â”€â”€ random_forest_*.pkl       # Otros modelos
â”œâ”€â”€ data/                   # ğŸ“Š Datasets
â”œâ”€â”€ notebooks/              # ğŸ“š AnÃ¡lisis exploratorio
â””â”€â”€ tests/                  # ğŸ§ª Pruebas automatizadas
```

## SoluciÃ³n de problemas comÃºn

- "ModuleNotFoundError" â€” activa el venv y reinstala dependencias: `pip install -r requirements.txt`.
- Problemas con Ollama â€” verificar versiÃ³n y que el servicio estÃ© corriendo: `ollama ps` / `ollama logs`.
- Frontend no arranca â€” revisa `node` y `npm` instalados, luego `npm install` y `npm run dev`.

## Buenas prÃ¡cticas

- MantÃ©n credenciales fuera del repositorio (.env en .gitignore).
- Versiona modelos con nombres que incluyan versiÃ³n y fecha cuando sean reentrenados.


## Contacto y crÃ©ditos

- Autor/es: Sebastian Matey, Liz Salazar, Roosevelt PÃ©rez â€” Instituto TecnolÃ³gico de Costa Rica (Sede San Carlos)
- Repo: ProyectoIA



